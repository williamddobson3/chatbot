# Model Configuration
MODEL_PATH=Qwen/Qwen2.5-72B-Instruct
MODEL_LOCAL_DIR=./models/Qwen2.5-72B-Instruct

# Device Configuration
DEVICE=cuda
# Use "cpu" if no GPU available

# Generation Parameters
MAX_LENGTH=2048
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=50

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=False

# Hugging Face Token (optional, for private models)
HF_TOKEN=

